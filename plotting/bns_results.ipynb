{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNS Results\n",
    "\n",
    "This notebook includes code to produces the figures and tables presented in\n",
    "section 5.2 which covers BNS analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the various modules we're going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from itertools import zip_longest\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "from IPython.display import HTML, display\n",
    "from matplotlib.lines import Line2D\n",
    "from pesummary.gw.plots.latex_labels import GWlatex_labels\n",
    "\n",
    "from gw_smc_utils.plotting import lighten_colour, set_style\n",
    "\n",
    "set_style()\n",
    "\n",
    "# There are some issues with plotting when using latex\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "\n",
    "Path(\"figures\").mkdir(exist_ok=True)\n",
    "Path(\"tables\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data release paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify paths to the data release and relevant files.\n",
    "\n",
    "Change these if you have downloaded the data release to a different path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_release_path = Path(\"../data_release/gw_smc_data_release_core\")\n",
    "bns_results = data_release_path / \"simulated_data\" / \"bns_results\"\n",
    "summary_path = bns_results / \"bns_results_summary.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jensen-Shannon Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the JSD results from the JSON file.\n",
    "\n",
    "Each JSON file contains the following keys:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"res1\": \"path to result file 1\",\n",
    "    \"res2\": \"path to result file 2\",\n",
    "    \"base\": 2,            # Base used in the calculation\n",
    "    \"seed\": 1234,         # The random seed\n",
    "    \"n_samples\": 5000,    # The number of samples\n",
    "    \"n_tests\": 10,        # The number of tests for bootstrapping errors\n",
    "    \"jsd\": {\n",
    "        \"chirp_mass\": [\n",
    "            ...\n",
    "        ],\n",
    "        \"mass_ratio\": [\n",
    "            ...\n",
    "        ],\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd_path = bns_results / \"jsd_results\"\n",
    "\n",
    "jsd_files = list(jsd_path.glob(\"*.json\"))\n",
    "if not jsd_files:\n",
    "    raise FileNotFoundError(\"No JSD files found in the specified directory.\")\n",
    "\n",
    "dets = [\"2det\", \"3det\"]\n",
    "labels = [\n",
    "    \"aligned_with_tides\",\n",
    "    \"aligned_without_tides\",\n",
    "    \"precessing_with_tides\",\n",
    "    \"precessing_without_tides\",\n",
    "]\n",
    "\n",
    "jsd_data = {}\n",
    "for det in dets:\n",
    "    jsd_data[det] = {}\n",
    "    for label in labels:\n",
    "        jsd_data[det][label] = {}\n",
    "        for jsd_file in jsd_files:\n",
    "            if det in jsd_file.name and label in jsd_file.name:\n",
    "                with open(jsd_file, \"r\") as f:\n",
    "                    jsd_data[det][label] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collate the results into a `pandas` `DataFrame` to make handling the results easier.\n",
    "\n",
    "We take the mean of the JSD values per-parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd_df = pd.DataFrame(columns=[\"ndet\", \"tides\", \"spin\"])\n",
    "for det in dets:\n",
    "    for label in labels:\n",
    "        dat = {\n",
    "            \"ndet\": det[0],\n",
    "            \"tides\": False if \"without\" in label else True,\n",
    "            \"spin\": \"aligned\" if \"aligned\" in label else \"precessing\",\n",
    "        }\n",
    "        for key, value in jsd_data[det][label][\"jsd\"].items():\n",
    "            dat[key] = value\n",
    "        dat = pd.DataFrame([dat])\n",
    "        jsd_df = pd.concat([jsd_df, dat], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures 9 & B4\n",
    "\n",
    "We make both figures using the same code and a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_labels = {}\n",
    "\n",
    "other_gw_labels = {\n",
    "    \"chi_1\": \"$\\\\chi_1$\",\n",
    "    \"chi_2\": \"$\\\\chi_2$\",\n",
    "}\n",
    "\n",
    "include_tides = [True, False]\n",
    "\n",
    "for tides in include_tides:\n",
    "    figsize = plt.rcParams[\"figure.figsize\"].copy()\n",
    "    figsize[1] = 2 * figsize[1]\n",
    "    fig, axs = plt.subplots(2, 1, figsize=figsize, sharex=True, height_ratios=[1, 1.4])\n",
    "\n",
    "    for ax, spin in zip(axs, [\"aligned\", \"precessing\"]):\n",
    "        subset = jsd_df[(jsd_df[\"spin\"] == spin) & (jsd_df[\"tides\"] == tides)]\n",
    "        all_parameters = subset.columns[3:]\n",
    "        parameters = all_parameters[~subset[all_parameters].isna().all()]\n",
    "        for p in parameters:\n",
    "            label = GWlatex_labels.get(p, other_gw_labels.get(p, p))\n",
    "            label = re.sub(r\"\\[.*?\\]\", \"\", label)\n",
    "            latex_labels[p] = label\n",
    "        yticks = np.arange(len(parameters))[::-1]\n",
    "        yoffset = 0.2\n",
    "\n",
    "        for j, ndet in enumerate([2, 3]):\n",
    "            df = jsd_df[jsd_df[\"spin\"] == spin]\n",
    "            df = df[df[\"tides\"] == tides]\n",
    "            df = df[df[\"ndet\"] == str(ndet)]\n",
    "            for i, p in enumerate(parameters):\n",
    "                data = 1000 * np.clip(np.array(df[p].values[0]), 0, 1)\n",
    "                mean = data.mean()\n",
    "                std = data.std()\n",
    "                offset = yoffset * (j - 0.5)\n",
    "                if spin == \"aligned\":\n",
    "                    colour = \"k\"\n",
    "                else:\n",
    "                    colour = \"k\"\n",
    "                if ndet == 2:\n",
    "                    colour = lighten_colour(colour, 0.5)\n",
    "                    marker = \"^\"\n",
    "                else:\n",
    "                    marker = \"o\"\n",
    "                ax.errorbar(\n",
    "                    mean,\n",
    "                    yticks[i] + offset,\n",
    "                    xerr=std,\n",
    "                    fmt=marker,\n",
    "                    label=latex_labels[p],\n",
    "                    c=colour,\n",
    "                )\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_yticks(yticks)\n",
    "            # Disable minor ticks\n",
    "            ax.set_yticks([], minor=True)\n",
    "            ax.set_yticklabels([latex_labels[p] for p in parameters])\n",
    "\n",
    "    axs[0].set_title(\"Aligned spin\")\n",
    "    axs[1].set_title(\"Precessing spin\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.axvline(2, color=\"k\", ls=\"--\")\n",
    "        ax.set_xlim(0.1, 30)\n",
    "\n",
    "    legend_handles = [\n",
    "        Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"w\",\n",
    "            markerfacecolor=\"k\",\n",
    "            markersize=5,\n",
    "            label=\"3\",\n",
    "            ls=\"\",\n",
    "        ),\n",
    "        Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"^\",\n",
    "            color=\"w\",\n",
    "            markerfacecolor=lighten_colour(\"k\", 0.5),\n",
    "            markersize=5,\n",
    "            label=\"2\",\n",
    "            ls=\"\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    axs[1].legend(\n",
    "        handles=legend_handles,\n",
    "        loc=\"lower right\",\n",
    "        fontsize=\"small\",\n",
    "        title=\"# detectors\",\n",
    "        title_fontsize=\"small\",\n",
    "    )\n",
    "\n",
    "    axs[-1].set_xlabel(r\"$D_{\\rm JS}$ [mbits]\")\n",
    "    filename = f\"bns_jsd_{'with' if tides else 'without'}_tides.pdf\"\n",
    "    fig.savefig(f\"figures/{filename}\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run statistics - Tables 1 & B1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the summary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "with h5py.File(summary_path, \"r\") as f:\n",
    "    for sampler in f.keys():\n",
    "        data[sampler] = {}\n",
    "        for ndetector in f[sampler].keys():\n",
    "            data[sampler][ndetector] = {}\n",
    "            for key in f[sampler][ndetector].keys():\n",
    "                data[sampler][ndetector][key] = {}\n",
    "                for stat in f[sampler][ndetector][key].keys():\n",
    "                    data[sampler][ndetector][key][stat] = f[sampler][ndetector][key][\n",
    "                        stat\n",
    "                    ][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to dynesty\n",
    "\n",
    "We compare the efficiency between the two samplers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = list(data.keys())\n",
    "ndets = list(data[samplers[0]].keys())\n",
    "\n",
    "# Ratio of dynesty to pocomc for number of likelihood evaluations per sample\n",
    "\n",
    "for ndetector in ndets:\n",
    "    for key in data[samplers[0]][ndetector]:\n",
    "        val0 = (\n",
    "            data[samplers[0]][ndetector][key][\"likelihood_evaluations\"]\n",
    "            / data[samplers[0]][ndetector][key][\"n_samples\"]\n",
    "        )\n",
    "        val1 = (\n",
    "            data[samplers[1]][ndetector][key][\"likelihood_evaluations\"]\n",
    "            / data[samplers[1]][ndetector][key][\"n_samples\"]\n",
    "        )\n",
    "        ratio = np.mean(val0) / np.mean(val1)\n",
    "        print(f\"{ndetector} {key} ratio: {ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the data\n",
    "\n",
    "Reformat the data into rows for the table.\n",
    "\n",
    "This includes taking the mean of the run statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for sampler, sampler_data in data.items():\n",
    "    for det, det_data in sampler_data.items():\n",
    "        for key, key_data in det_data.items():\n",
    "            if \"precessing\" in key.lower():\n",
    "                precessing = True\n",
    "            else:\n",
    "                precessing = False\n",
    "            if \"with_tides\" in key.lower():\n",
    "                tides = True\n",
    "            else:\n",
    "                tides = False\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"sampler\": sampler,\n",
    "                    \"det\": det,\n",
    "                    \"key\": key,\n",
    "                    \"tides\": tides,\n",
    "                    \"precessing\": precessing,\n",
    "                    \"likelihood_evaluations\": float(\n",
    "                        np.mean(key_data[\"likelihood_evaluations\"])\n",
    "                    ),\n",
    "                    \"sampling_time\": float(np.mean(key_data[\"sampling_time\"] / 60)),\n",
    "                    \"likelihood_evaluations_per_sample\": float(\n",
    "                        np.mean(\n",
    "                            key_data[\"likelihood_evaluations\"] / key_data[\"n_samples\"]\n",
    "                        )\n",
    "                    ),\n",
    "                    \"sampling_time_per_sample\": float(\n",
    "                        np.mean(key_data[\"sampling_time\"] / 60 / key_data[\"n_samples\"])\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Define group order\n",
    "# Order: (precessing, tides)\n",
    "group_order = [\n",
    "    (False, False),\n",
    "    (False, True),\n",
    "    (True, False),\n",
    "    (True, True),\n",
    "]\n",
    "\n",
    "\n",
    "# Helper to interleave rows\n",
    "def interleave_group(group_df):\n",
    "    grouped = [\n",
    "        g[1].sort_values(\"det\").to_dict(orient=\"records\")\n",
    "        for g in group_df.groupby(\"sampler\")\n",
    "    ]\n",
    "    interleaved = []\n",
    "    for row_group in zip_longest(*grouped):\n",
    "        interleaved.extend(r for r in row_group if r is not None)\n",
    "    return interleaved\n",
    "\n",
    "\n",
    "# Process all groups and interleave\n",
    "final_rows = []\n",
    "for precessing, tides in group_order:\n",
    "    group_df = df[(df[\"precessing\"] == precessing) & (df[\"tides\"] == tides)]\n",
    "    final_rows.extend(interleave_group(group_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Table\n",
    "\n",
    "Below, the tabled is visualized in HTML using the `tabulate` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = tabulate.tabulate(final_rows, headers=\"keys\", tablefmt=\"html\")\n",
    "display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex tables\n",
    "\n",
    "We then generate the latex tables for the paper.\n",
    "\n",
    "These are written to files in the `tables` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = defaultdict(\n",
    "    lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    ")\n",
    "\n",
    "for ndet in [2, 3]:\n",
    "    data = []\n",
    "    for row in final_rows:\n",
    "        if row[\"det\"] == f\"{ndet}det\":\n",
    "            continue\n",
    "        else:\n",
    "            data.append(row)\n",
    "\n",
    "    def format_sci_latex(x, precision=2):\n",
    "        \"\"\"Format number in LaTeX-style scientific notation.\"\"\"\n",
    "        if x == 0:\n",
    "            return f\"${0:.{precision}f}$\"\n",
    "        exponent = int(np.floor(np.log10(abs(x))))\n",
    "        mantissa = x / (10**exponent)\n",
    "        return f\"${mantissa:.{precision}f} \\\\times 10^{{{exponent}}}$\"\n",
    "\n",
    "    # Function to format a row (can average if needed)\n",
    "    def format_cell(entry, keys):\n",
    "        if not entry:\n",
    "            return [\"--\"] * len(keys)\n",
    "        out = []\n",
    "        for key in keys:\n",
    "            v = entry[key]\n",
    "            if key == \"likelihood_evaluations\":\n",
    "                out.append(format_sci_latex(v, 1))\n",
    "            elif key == \"sampler\":\n",
    "                out.append(r\"\\texttt{\" + v + \"}\")\n",
    "            elif isinstance(v, float):\n",
    "                out.append(f\"{v:.4g}\")\n",
    "            elif isinstance(v, bool):\n",
    "                if v:\n",
    "                    out.append(r\"\\cmark\")\n",
    "                else:\n",
    "                    out.append(r\"\\xmark\")\n",
    "\n",
    "            else:\n",
    "                out.append(str(v))\n",
    "        return out\n",
    "\n",
    "    # Build LaTeX table\n",
    "    header = r\"\"\"\n",
    "    \\begin{tabular}{lcccccc}\n",
    "    \\toprule\n",
    "    Sampler & Precession & Tides & Likelihood evaluations & Wall time [min] & Likelihood evaluations per sample \\\\\n",
    "    \\midrule\n",
    "    \"\"\"\n",
    "\n",
    "    latex_rows = []\n",
    "    for r in data:\n",
    "        row = format_cell(\n",
    "            r,\n",
    "            keys=[\n",
    "                \"sampler\",\n",
    "                \"precessing\",\n",
    "                \"tides\",\n",
    "                \"likelihood_evaluations\",\n",
    "                \"sampling_time\",\n",
    "                \"likelihood_evaluations_per_sample\",\n",
    "            ],\n",
    "        )\n",
    "        if r[\"sampler\"] == \"dynesty\":\n",
    "            latex_rows.append(r\"\\rowcolor{lightgrey}\" + \" & \".join(row) + r\" \\\\\")\n",
    "        else:\n",
    "            latex_rows.append(\" & \".join(row) + r\" \\\\\")\n",
    "\n",
    "    footer = r\"\"\"\n",
    "    \\bottomrule\n",
    "    \\end{tabular}\n",
    "    \"\"\"\n",
    "\n",
    "    latex_table = header + \"\\n\".join(latex_rows) + footer\n",
    "\n",
    "    with open(\n",
    "        f\"tables/bns_sampling_time_vs_likelihood_evaluations_{ndet}det.tex\", \"w\"\n",
    "    ) as f:\n",
    "        f.write(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw-smc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
